{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fecc472d-bfec-4581-9783-3470362cc93e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"A multi-label classifier, part 5: finding duplicate images\"\n",
    "date: \"2023-03-11\"\n",
    "date-modified: \"2023-03-12\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "    code-tools:\n",
    "      source: https://github.com/sswam/ai/blob/main/blog/posts/multilabel5/multilabel5.ipynb\n",
    "jupyter: python\n",
    "toc: true\n",
    "toc-depth: 2\n",
    "categories: []\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dceede-e5c2-43ac-8409-cac22f237ed4",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3b85e-f34f-406c-97b7-a7f8382b50a2",
   "metadata": {},
   "source": [
    "## check for exact duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c99cff-80d4-48c9-93f6-9d08c8f1e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -al bird_cat_dog.3.together bird_cat_dog.4.dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d98ee-3af1-42bd-91bd-d61db24354bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sam/ai/blog/posts/multilabel/bird_cat_dog.4.dedup\n"
     ]
    }
   ],
   "source": [
    "cd bird_cat_dog.4.dedup/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0cc2ae-6709-430b-a083-bf85916d9189",
   "metadata": {},
   "source": [
    "Automatically delete duplicates with the same labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0c6b7-3831-44ba-b4cb-a7cb107891c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        \r"
     ]
    }
   ],
   "source": [
    "!for d in *; do fdupes -f -r $d; done | grep . | xa rm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee49a1-df67-4608-a1ac-c518b10b17a6",
   "metadata": {},
   "source": [
    "Manually delete duplicates with different labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae1f48-0caf-4946-a986-87e27fc297cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        \r"
     ]
    }
   ],
   "source": [
    "!fdupes -r . | grep . | xa qiv -D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275e2740-6e1f-4298-bf26-ae2d4ddac242",
   "metadata": {},
   "source": [
    "## check for similar images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905dacc-cf3b-485e-86d6-59e010d07a0e",
   "metadata": {},
   "source": [
    "Ideally, I would show each set of duplicates together across a row, visually check them, eliminate any that aren't in fact duplicates, and keep the best quality image from each set. I might not be able to determine which is best quality automatically after having resized them, so I might need to do step before resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d798d1f-7098-4cd7-954f-bee43a29f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!findimagedupes -R -f dups.db . >dups.txt 2>dups.err.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04994bbd-db54-4e42-9d06-fb2dfbd30066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: dups.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!< dups.txt xargs qiv -D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
